{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T10:16:05.942263Z",
     "start_time": "2019-11-15T10:16:03.750591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tao Yang\\AppData\\Roaming\\Python\\Python36\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Tao Yang\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Tao Yang\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Tao Yang\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Tao Yang\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Tao Yang\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Tao Yang\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Input, Dense, Conv2D, Flatten,Reshape,Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T10:16:16.912252Z",
     "start_time": "2019-11-15T10:16:07.938446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the dataset: KeysView(<numpy.lib.npyio.NpzFile object at 0x0000012BD23AE908>)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_zip = np.load('dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz')\n",
    "\n",
    "print('Keys in the dataset:', dataset_zip.keys())\n",
    "imgs = dataset_zip['imgs']\n",
    "latents_values = dataset_zip['latents_values']\n",
    "latents_classes = dataset_zip['latents_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T10:16:33.392837Z",
     "start_time": "2019-11-15T10:16:16.913238Z"
    }
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, y_train, x_test, y_test = train_test_split(imgs,latents_values)\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size * image_size\n",
    "x_train = np.reshape(x_train, [-1, 64,64,1])\n",
    "x_test = np.reshape(x_test, [-1, 64,64,1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T11:09:28.492913Z",
     "start_time": "2019-11-15T11:09:28.487904Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T11:11:40.354732Z",
     "start_time": "2019-11-15T11:11:39.776052Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Cov1 (Conv2D)                   (None, 32, 32, 32)   544         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Cov2 (Conv2D)                   (None, 16, 16, 32)   16416       Cov1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Cov3 (Conv2D)                   (None, 8, 8, 32)     16416       Cov2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Cov4 (Conv2D)                   (None, 4, 4, 32)     16416       Cov3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 512)          0           Cov4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 256)          131328      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 256)          65792       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 10)           2570        Dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 10)           2570        Dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 10)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 252,052\n",
      "Trainable params: 252,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "deDense1 (Dense)             (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "deDense2 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "deDense3 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "DeCov1 (Conv2DTranspose)     (None, 8, 8, 32)          16416     \n",
      "_________________________________________________________________\n",
      "DeCov2 (Conv2DTranspose)     (None, 16, 16, 32)        16416     \n",
      "_________________________________________________________________\n",
      "DeCov3 (Conv2DTranspose)     (None, 32, 32, 32)        16416     \n",
      "_________________________________________________________________\n",
      "DeCov4 (Conv2DTranspose)     (None, 64, 64, 1)         513       \n",
      "=================================================================\n",
      "Total params: 249,953\n",
      "Trainable params: 249,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network parameters\n",
    "nc = 1\n",
    "input_shape = (64,64,nc)\n",
    "intermediate_dim = 512\n",
    "batch_size = 128\n",
    "latent_dim = 10\n",
    "epochs = 1\n",
    "beta = 20\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Conv2D(kernel_size = 4,filters=32,padding=\"same\",strides=2,activation=\"relu\",name = \"Cov1\")(inputs)\n",
    "x = Conv2D(kernel_size = 4,filters=32,padding=\"same\",strides=2,activation=\"relu\",name = \"Cov2\")(x)\n",
    "x = Conv2D(kernel_size = 4,filters=32,padding=\"same\",strides=2,activation=\"relu\",name = \"Cov3\")(x)\n",
    "x = Conv2D(kernel_size = 4,filters=32,padding=\"same\",strides=2,activation=\"relu\",name = \"Cov4\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, name='Dense1',activation=\"relu\")(x)\n",
    "x = Dense(256, name='Dense2',activation=\"relu\")(x)\n",
    "z_mean = Dense(latent_dim,name = \"z_mean\")(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(256, activation='relu',name = \"deDense1\")(latent_inputs)\n",
    "x = Dense(256, activation='relu',name = \"deDense2\")(x)\n",
    "x = Dense(32*4*4, activation='relu',name = \"deDense3\")(x)\n",
    "x = Reshape((4,4,32))(x)\n",
    "x = Conv2DTranspose(kernel_size = 4,padding=\"same\",strides=2,filters = 32,name=\"DeCov1\")(x)\n",
    "x = Conv2DTranspose(kernel_size = 4,padding=\"same\",strides=2,filters = 32,name=\"DeCov2\")(x)\n",
    "x = Conv2DTranspose(kernel_size = 4,padding=\"same\",strides=2,filters = 32,name=\"DeCov3\")(x)\n",
    "outputs = Conv2DTranspose(kernel_size = 4,padding=\"same\",strides=2,filters = nc,name=\"DeCov4\")(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T11:11:40.532634Z",
     "start_time": "2019-11-15T11:11:40.491640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 10), (None, 10),  252052    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 64, 64, 1)         249953    \n",
      "=================================================================\n",
      "Total params: 502,005\n",
      "Trainable params: 502,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "is_mse = False\n",
    "# VAE loss = mse_loss or xent_loss + kl_loss\n",
    "if is_mse:\n",
    "    reconstruction_loss = mse(inputs, outputs)\n",
    "else:\n",
    "    reconstruction_loss = binary_crossentropy(inputs,\n",
    "                                              outputs)\n",
    "\n",
    "reconstruction_loss *= original_dim\n",
    "reconstruction_loss = K.reshape(reconstruction_loss,(-1,64*64))\n",
    "reconstruction_loss = K.mean(reconstruction_loss,axis=1)\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + beta*kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T11:39:29.553825Z",
     "start_time": "2019-11-15T11:11:41.317941Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081b4f16345744d1b284a5c9e73f2e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in BetaVAE.000.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the autoencoder\n",
    "np.random.seed(2019)\n",
    "tf.set_random_seed(2019)\n",
    "model_filename = 'BetaVAE.{0:03d}.h5'\n",
    "last_finished_epoch = 0\n",
    "# vae = load_model(model_filename.format(last_finished_epoch))\n",
    "vae.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None),\n",
    "       callbacks=[keras_utils.ModelSaveCallback(model_filename),\n",
    "                 keras_utils.TqdmProgressCallback()],\n",
    "        verbose=0)\n",
    "vae.save_weights('vae_beta_dsprites.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T11:07:28.534103Z",
     "start_time": "2019-11-15T11:07:28.049355Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When passing a list as loss, it should have one entry per model outputs. The model has 1 outputs, but you passed loss=[]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4b22bd46d4e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# disable dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlast_finished_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_finished_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[1;34m(f, custom_objects, compile)\u001b[0m\n\u001b[0;32m    310\u001b[0m                       \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                       \u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                       sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;31m# Set optimizer weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m                                  \u001b[1;34m'The model has '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                                  \u001b[1;34m' outputs, but you passed loss='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                                  str(loss))\n\u001b[0m\u001b[0;32m    137\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: When passing a list as loss, it should have one entry per model outputs. The model has 1 outputs, but you passed loss=[]"
     ]
    }
   ],
   "source": [
    "from keras_utils import reset_tf_session\n",
    "from keras.models import load_model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "K.set_learning_phase(0)  # disable dropout\n",
    "last_finished_epoch = 0\n",
    "model = load_model(model_filename.format(last_finished_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maximum_stimuli(k,model, iterations=20, step=1., verbose=True):\n",
    "    \n",
    "    def image_values_to_rgb(x):\n",
    "        # normalize x: center on 0 (np.mean(x_train2)), ensure std is 0.25 (np.std(x_train2))\n",
    "        # so that it looks like a normalized image input for our network\n",
    "        x = (x -np.mean(x))/np.std(x_train2) ### YOUR CODE HERE\n",
    "\n",
    "        # do reverse normalization to RGB values: x = (x_norm + 0.5) * 255\n",
    "        x = x*255### YOUR CODE HERE\n",
    "    \n",
    "        # clip values to [0, 255] and convert to bytes\n",
    "        x = np.clip(x, 0, 255).astype('uint8')\n",
    "        return x\n",
    "\n",
    "    # this is the placeholder for the input image\n",
    "    z_tar = Input(shape=(latent_dim,))\n",
    "    input_img = model.input\n",
    "    img_width, img_height = input_img.shape.as_list()[1:3]\n",
    "    \n",
    "    # find the layer output by name\n",
    "    _,_,z = model.encoder(input_img)\n",
    "    \n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the filter_index filter of the layer considered\n",
    "    loss = mse(z_tar,z)\n",
    "\n",
    "    # we compute the gradient of the loss wrt input image\n",
    "    grads = K.gradients(loss, input_img)[0]  # [0] because of the batch dimension!\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = grads / (K.sqrt(K.sum(K.square(grads))) + 1e-10)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img,z_tar], [loss, grads])\n",
    "    get_output = K.function([input_img], [z])\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    input_img_data = x_train[0]\n",
    "\n",
    "    # we run gradient ascent\n",
    "    I = np.eye(latent_dim)\n",
    "    for i in range(iterations):\n",
    "        z_ = get_output([input_img_data])\n",
    "        if i == 0:\n",
    "            z_ = z_ + I[k,:]\n",
    "        loss, grads = iterate([input_img_data,z_])\n",
    "        input_img_data += grads_value * step\n",
    "        if verbose:\n",
    "            print('Current loss value:', loss_value)\n",
    "\n",
    "    # decode the resulting input image\n",
    "    img = image_values_to_rgb(input_img_data[0])\n",
    "    \n",
    "    return img, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample maximum stimuli\n",
    "def plot_filters_stimuli(model, iterations=20, step=1., verbose=False):\n",
    "    fig = plt.figure()\n",
    "    loss = -1e20\n",
    "    for i in range(latent_dim):\n",
    "        ax = fig.add_subplot(1, latent_dim, i)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        stimuli, loss = find_maximum_stimuli(i,model,iterations, step, verbose=verbose)\n",
    "        ax.imshow(stimuli)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filters_stimuli(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
